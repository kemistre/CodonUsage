{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import minmax_scale"]},{"cell_type":"markdown","metadata":{},"source":["# Download the date\n","https://archive.ics.uci.edu/ml/machine-learning-databases/00577/codon_usage.csv.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00577/codon_usage.csv.zip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !unzip codon_usage.csv.zip"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_data(file_name):\n","    \"\"\"\n","    Reads in a csv file and returns a dataframe\n","    \"\"\"\n","    return pd.read_csv(file_name, low_memory=False)\n","\n","dataset = read_data('codon_usage.csv')\n","df = dataset.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dataset = read_data('codon_usage.csv')\n","dataset.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dataset.dropna(inplace=True)\n","\n","dataset['Kingdom'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(dataset.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset['Kingdom'].value_counts().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset['Kingdom'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset['Kingdom'] = dataset['Kingdom'].map({   'arc': 0, 'bct': 1, \n","                                                'phg': 2, 'plm': 3, \n","                                                'pln': 4, 'inv': 5, \n","                                                'vrt': 6, 'mam': 7,\n","                                                'rod': 8, 'pri': 9, 'vrl':10})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset['Kingdom'].value_counts().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = dataset.drop(dataset[dataset['SpeciesID']==353569].index)\n","dataset = dataset.drop(dataset[dataset['SpeciesID']==1238].index)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = dataset.iloc[:, 5:].values.astype(float)\n","y = dataset.iloc[:, 0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset['DNAtype'].value_counts().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class GaussianNaiveBayes:\n","  def __init__(self, X, y, laplace_smoothing_value, discrete, laplace, classes):\n","    # update your Naive Bayes class functions to account for a discrete classification using what we have learned in the class. \n","    self.X =X # training data\n","    self.y = y # y is the original classes\n","    self.laplace_smoothing_value = laplace_smoothing_value # laplace smoothing value\n","    self.discrete = discrete # boolean variable to indicate if the data is discrete or continuous\n","    self.laplace = laplace  # boolean for laplace smoothing\n","    self.classes = classes  # this is the number of classes in the data\n","\n","\n","\n","  def splitData(self):\n","    X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=1)\n","    print('Training data size: ', X_train.shape) # (890, 10)\n","    print('Test data size: ', X_test.shape) # (190, 10)\n","    return X_train, X_test, y_train, y_test # return the training and test data \n","\n","\n","\n","  def fitDistribution(self, data):\n","\n","    mean = np.mean(data) # mean of the data\n","    std = np.std(data) # standard deviation of the data\n","\n","    dist = norm(mean, std) # create a normal distribution with the mean and standard deviation \n","\n","    return dist # return the distribution\n","\n","\n","\n","  def laplaceSmoothing(self, classes, length):\n","    # print('type 0 ', type(class0))\n","    # print('size 0 ', class0.size)\n","    # print('type 1 ', type(class1))\n","    # print('size 1 ', class1.size)\n","    # smooth0 = (class0 + self.laplace_smoothing_value) / ( (class0.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth1 = (class1 + self.laplace_smoothing_value) / ( (class1.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth2 = (class2 + self.laplace_smoothing_value) / ( (class2.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth3 = (class3 + self.laplace_smoothing_value) / ( (class3.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth4 = (class4 + self.laplace_smoothing_value) / ( (class4.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth5 = (class5 + self.laplace_smoothing_value) / ( (class5.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth6 = (class6 + self.laplace_smoothing_value) / ( (class6.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth7 = (class7 + self.laplace_smoothing_value) / ( (class7.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth8 = (class8 + self.laplace_smoothing_value) / ( (class8.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth9 = (class9 + self.laplace_smoothing_value) / ( (class9.size) + self.laplace_smoothing_value * self.n_features)\n","    # smooth10 = (class10 + self.laplace_smoothing_value) / ( (class10.size) + self.laplace_smoothing_value * self.n_features)\n","    smooths = [] # create an empty list to store the smoothed values\n","    for i in range(length): \n","      # add the laplace smoothing value to the class and divide by the size of the class plus the laplace smoothing value times the number of features\n","      smooths[i] = (classes[i] + self.laplace_smoothing_value) / ( (classes[i].size) + self.laplace_smoothing_value * self.n_features) \n","    \n","    # return the smoothed values\n","    \n","    return smooths \n","  \n","\n","\n","\n","  def evaluate(self, y, y_predicted):\n","    '''\n","\n","      Takes original classes and predicted classes as input\n","\n","      Return the values of precision, recall and accuracy\n","    \n","    '''\n","    y = ( y==1 )\n","    y_predicted = ( y_predicted == 1 )\n","\n","    precision = (y&y_predicted).sum() / y_predicted.sum()\n","    recall = (y&y_predicted).sum() / y.sum()\n","    accuracy = (y==y_predicted).sum() / y.size\n","\n","\n","    return precision, recall, accuracy\n","\n","\n","\n","  # def probability(self, X, dist1, dist2, prior):\n","  #   return prior * ( dist1.pdf(X[0]) *  dist2.pdf(X[1]))\n","\n","\n","  def probability(self, data):\n","    # py0 = 1\n","    # py1 = 1\n","    py = np.ones(11) # create an array of ones to store the probabilities\n","\n","\n","    if self.discrete:\n","      for i in range(self.n_features): # for each feature\n","        # py[0] *= self.laplaceSmoothing(self.class0[i], self.n_features)\n","\n","        for j in range(11): # for each class\n","          print('i, j ', i, j) # print the feature and class\n","          # multiply the probability by the probability of the feature given the class\n","          py[j] *= self.features['X'+str(i)+str(j)] \n","\n","        # py0 *= self.features['X'+str(i)+str(data[i])+'0']\n","        # py1 *= self.features['X'+str(i)+str(data[i])+'1']\n","        # py2 *= self.features['X'+str(i)+str(data[i])+'2']\n","        # py3 *= self.features['X'+str(i)+str(data[i])+'3']\n","        # py4 *= self.features['X'+str(i)+str(data[i])+'4']\n","        # py5 *= self.features['X'+str(i)+str(data[i])+'5']\n","\n","    else:\n","      for i in range(self.n_features):\n","        for j in range(11):\n","          py[j] *= self.features['X'+str(i)+str(j)].pdf(data[i])\n","        # py0 *= self.features['X'+str(i)+'0'].pdf(data[i])\n","        # py1 *= self.features['X'+str(i)+'1'].pdf(data[i])\n","\n","    for i in range(11):\n","      py[i] *= self.prior[i]\n","    \n","    return  py\n","\n","\n","\n","  def laplaceProbability(self, data):\n","    # py0 = 1\n","    # py1 = 1\n","\n","    py = np.ones(11) # create an array of ones to store the probabilities\n","\n","    if self.discrete:\n","      for i in range(self.n_features):\n","        print(data[i])\n","        print('X'+str(i)+'0')\n","        smooths = self.laplaceSmoothing(self.features, self.n_features)\n","        class0 = self.features['X'+str(i)+'0']\n","        smooth0 , smooth1, smooth2, smooth3, smooth4, smooth5, smooth6, smooth7, smooth8, smooth9, smooth10 = self.laplaceSmoothing( class0 = self.features['X'+str(i)+'0'], class1 = self.features['X'+str(i)+'1'], class2 = self.features['X'+str(i)+'2'], \n","                                                    class3 = self.features['X'+str(i)+'3'], class4 = self.features['X'+str(i)+'4'], class5 = self.features['X'+str(i)+'5'], \n","                                                    class6 = self.features['X'+str(i)+'6'], class7 = self.features['X'+str(i)+'7'], class8 = self.features['X'+str(i)+'8'], \n","                                                    class9 = self.features['X'+str(i)+'9'], class10 = self.features['X'+str(i)+'10'])\n","        print(smooth0, smooth1, smooth2, smooth3, smooth4, smooth5, smooth6, smooth7, smooth8, smooth9, smooth10)\n","        py0 *= smooth0\n","        py1 *= smooth1\n","        py2 *= smooth2\n","        py3 *= smooth3\n","        py4 *= smooth4\n","        py5 *= smooth5\n","        py6 *= smooth6\n","        py7 *= smooth7\n","        py8 *= smooth8\n","        py9 *= smooth9\n","        py10 *= smooth10\n","    \n","    else:\n","      for i in range(self.n_features):\n","        pdf0 = self.features['X'+str(i)+'0'].pdf(data[i])\n","        pdf1 = self.features['X'+str(i)+'1'].pdf(data[i])\n","        pdf2 = self.features['X'+str(i)+'2'].pdf(data[i])\n","        pdf3 = self.features['X'+str(i)+'3'].pdf(data[i])\n","        pdf4 = self.features['X'+str(i)+'4'].pdf(data[i])\n","        pdf5 = self.features['X'+str(i)+'5'].pdf(data[i])\n","        pdf6 = self.features['X'+str(i)+'6'].pdf(data[i])\n","        pdf7 = self.features['X'+str(i)+'7'].pdf(data[i])\n","        pdf8 = self.features['X'+str(i)+'8'].pdf(data[i])\n","        pdf9 = self.features['X'+str(i)+'9'].pdf(data[i])\n","        pdf10 = self.features['X'+str(i)+'10'].pdf(data[i])\n","        smooth0 , smooth1, smooth2, smooth3, smooth4, smooth5, smooth6, smooth7, smooth8, smooth9, smooth10  = self.laplaceSmoothing(pdf0, pdf1, pdf2, pdf3, pdf4, pdf5, pdf6, pdf7, pdf8, pdf9, pdf10)\n","        py0 *= smooth0\n","        py1 *= smooth1\n","        py2 *= smooth2\n","        py3 *= smooth3\n","        py4 *= smooth4\n","        py5 *= smooth5\n","        py6 *= smooth6\n","        py7 *= smooth7\n","        py8 *= smooth8\n","        py9 *= smooth9\n","        py10 *= smooth10\n","\n","\n","    return  py0 * self.prior_0, py1 * self.prior_1, py2 * self.prior_2, py3 * self.prior_3, py4 * self.prior_4, py5 * self.prior_5, py6 * self.prior_6, py7 * self.prior_7, py8 * self.prior_8, py9 * self.prior_9, py10 * self.prior_10                                                                            \n","\n","\n","\n","\n","  def fit(self):\n","\n","    self.X_train, self.X_test, self.y_train, self.y_test = self.splitData()\n","    X_training = self.X_train.copy()\n","    for i in range(self.classes):\n","      X_training[i] = self.X_train[self.y_train == i]\n","      self.prior[i] = len(X_training[i]) / len(self.X_train)\n","\n","    # X0_train = self.X_train[self.y_train == 0]\n","    # X1_train = self.X_train[self.y_train == 1]\n","    # X2_train = self.X_train[self.y_train == 2]\n","    # X3_train = self.X_train[self.y_train == 3]\n","    # X4_train = self.X_train[self.y_train == 4]\n","    # X5_train = self.X_train[self.y_train == 5]\n","    # X6_train = self.X_train[self.y_train == 6]\n","    # X7_train = self.X_train[self.y_train == 7]\n","    # X8_train = self.X_train[self.y_train == 8]\n","    # X9_train = self.X_train[self.y_train == 9]\n","    # X10_train = self.X_train[self.y_train == 10]\n","\n","    for i in range(self.classes):\n","      self.prior[i] = len(X_training[i]) / len(self.X_train)\n","\n","    # self.prior_1 = len(X1_train) / len(self.X_train)\n","    # self.prior_0 = len(X0_train) / len(self.X_train)\n","    # self.prior_2 = len(X2_train) / len(self.X_train)\n","    # self.prior_3 = len(X3_train) / len(self.X_train)\n","    # self.prior_4 = len(X4_train) / len(self.X_train)\n","    # self.prior_5 = len(X5_train) / len(self.X_train)\n","    # self.prior_6 = len(X6_train) / len(self.X_train)\n","    # self.prior_7 = len(X7_train) / len(self.X_train)\n","    # self.prior_8 = len(X8_train) / len(self.X_train)\n","    # self.prior_9 = len(X9_train) / len(self.X_train)\n","    # self.prior_10 = len(X10_train) / len(self.X_train)\n","    \n","\n","\n","    self.n_features = self.X_train.shape[1]\n","    print('Number of features: ', self.n_features)\n","    self.features = {}\n","    \n","    if self.discrete:\n","\n","      print('Discrete Data')\n","\n","      for i in range(self.n_features):\n","        for j in range(self.n_classes):\n","          for k in range(self.n_classes):\n","            self.features['X'+str(i)+str(j)+str(k)] = ( X_training[i][X_training[:,i] == j] ) / len(X_training[i])\n","\n","        # self.features['X'+str(i)+'00'] = ( (X0_train[ X0_train[:,i]==0 ]).sum() ) / len(X0_train)\n","        # self.features['X'+str(i)+'01'] = ( (X0_train[ X0_train[:,i]==0 ]).sum() ) / len(X1_train)\n","        # self.features['X'+str(i)+'10'] = ( (X0_train[ X0_train[:,i]==1 ]).sum() ) / len(X0_train)\n","        # self.features['X'+str(i)+'11'] = ( (X0_train[ X0_train[:,i]==1 ]).sum() ) / len(X1_train)\n","\n","    \n","    else:\n","\n","      print('Continuous Data')\n","\n","      for i in range(self.n_features):\n","        for j in range(self.n_classes):\n","          self.features['X'+str(i)+str(j)] = self.fitDistribution(X_training[j][:,i])\n","          \n","        # self.features['X'+str(i)+'0'] = self.fitDistribution(X0_train[:, i])\n","        # self.features['X'+str(i)+'1'] = self.fitDistribution(X1_train[:, i])\n","\n","\n","    # self.X00_dist = self.fitDistribution(X0_train[:, 0])\n","    # self.X01_dist = self.fitDistribution(X0_train[:, 1])\n","\n","    # self.X10_dist = self.fitDistribution(X1_train[:, 0])\n","    # self.X11_dist = self.fitDistribution(X1_train[:, 1])\n","\n","  \n","  \n","  def predict(self):\n","    count = 0\n","    y_predicted = []\n","    y = []\n","    for sample, target in zip(self.X_test, self.y_test):\n","      # py0 = self.probability(sample, self.X00_dist, self.X01_dist, self.prior_0)\n","      # py1 = self.probability(sample, self.X10_dist, self.X11_dist, self.prior_1)\n","\n","      # print(\"P(y=0|%s = %.3f\" % (sample, py0*100))\n","      # print(\"P(y=1|%s = %.3f\" % (sample, py1*100))\n","\n","      if self.laplace:\n","        py0, py1 = self.laplaceProbability(sample)\n","      \n","      else:\n","        py0, py1 = self.probability(sample)\n","\n","      print(\"Model predicted class {} and truth was {}\".format(np.argmax([py0,py1]), target))\n","      y_predicted.append(np.argmax([py0,py1]))\n","      y.append(target)\n","      # np.append(y_predicted, np.argmax([py0,py1]))\n","      # np.append(y, target)\n","      # y = target\n","      if np.argmax([py0,py1]) != target :\n","        count+=1\n","\n","      # precision, recall, accuracy = self.evaluate(y, y_predicted)\n","      # print(\"precision:\", precision)\n","      # print(\"recall:\", recall)\n","      # print(\"accuracy:\", accuracy)\n","\n","    \n","    print(count)\n","    # print(y)\n","    y_predicted = np.array(y_predicted)\n","    y = np.array(y)\n","\n","    precision, recall, accuracy = self.evaluate(y, y_predicted)\n","    print(\"precision:\", precision)\n","    print(\"recall:\", recall)\n","    print(\"accuracy:\", accuracy)\n","    print(\"f1 score:\", 2*(precision*recall)/(precision+recall))\n","    print(set(y_predicted))\n","\n","      \n","\n","  \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = GaussianNaiveBayes(X,y, laplace_smoothing_value=0.5, discrete=False, laplace=True, classes=2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf.fit()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf.predict()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('.env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"20f3b51db45487e76e19b963685aeaff4d2f53ee3a54c0a9156da0ef575c3172"}}},"nbformat":4,"nbformat_minor":2}
