{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Download the date\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00577/codon_usage.csv.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00577/codon_usage.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !unzip codon_usage.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    \"\"\"\n",
    "    Reads in a csv file and returns a dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_name, low_memory=False)\n",
    "\n",
    "dataset = read_data('codon_usage.csv')\n",
    "df = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = read_data('codon_usage.csv')\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.dropna(inplace=True)\n",
    "\n",
    "dataset['Kingdom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset['Kingdom'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes_dict = {    'arc': 0, 'bct': 1, 'phg': 2, 'plm': 3, \n",
    "                    'pln': 4, 'inv': 5, 'vrt': 6, 'mam': 7,\n",
    "                    'rod': 8, 'pri': 9, 'vrl':10\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset['Kingdom'] = dataset['Kingdom'].map(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset['Kingdom'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop(dataset[dataset['SpeciesID']==353569].index)\n",
    "dataset = dataset.drop(dataset[dataset['SpeciesID']==1238].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset['UUU'] = dataset['UUU'].astype(float)\n",
    "dataset['UUC'] = dataset['UUC'].astype(float)\n",
    "# dataset = minmax_scale(dataset)\n",
    "# cols = dataset.select_dtypes(np.number).columns\n",
    "\n",
    "# num_columns_list = list(cols)\n",
    "# # num_columns_list\n",
    "\n",
    "# num_columns_list.remove('Kingdom')\n",
    "# # num_columns_list.remove('DNAtype')\n",
    "# num_columns_list.remove('SpeciesID')\n",
    "# # num_columns_list.remove('Ncodons')\n",
    "# # num_columns_list\n",
    "\n",
    "# Removing the minmax_scale of the columns because it is not necessary it might lead to 0\n",
    "# for num_column in num_columns_list:\n",
    "#     dataset[num_column] = minmax_scale(dataset[num_column]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:]\n",
    "X.drop(['SpeciesName', 'SpeciesID', 'DNAtype', 'Ncodons'], axis=1, inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = X.values.astype(float)\n",
    "y = dataset.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "\n",
    "    def __init__(self, X, y, sampleSize=16):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.sampleSize = sampleSize\n",
    "        if self.sampleSize <= 0 and self.sampleSize > len(self.X):\n",
    "            return TypeError(\"sampleSize must be between 0 and \", len(X))\n",
    "\n",
    "    def split_data(self, test_size=0.3, random_state=1):\n",
    "        self.X_train, self.X_rem, self.y_train, self.y_rem = tts(self.X, self.y, test_size=test_size, random_state=random_state)\n",
    "        return self.X_train, self.X_rem, self.y_train, self.y_rem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(y=y, X=X)\n",
    "X_training, X_testing, y_training, y_testing = data_generator.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sampler(X, y, technique):\n",
    "    if technique =='ros':\n",
    "        ros = RandomOverSampler(random_state=1)\n",
    "        X_training, y_training = ros.fit_resample(X, y)\n",
    "    \n",
    "    elif technique =='smote':\n",
    "        smoothing = SMOTE(random_state=1)\n",
    "        X_training, y_training = smoothing.fit_resample(X, y)\n",
    "    \n",
    "    elif technique =='adasyn':\n",
    "        adasyn = ADASYN(random_state=1)\n",
    "        X_training, y_training = adasyn.fit_resample(X, y)\n",
    "    \n",
    "    return X_training, y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassClassification:\n",
    "    def __init__(self, X_train, y_train, laplace_smoothing_value, laplace, total_classes=11):\n",
    "        self.laplace_smoothing_value = laplace_smoothing_value\n",
    "        self.laplace = laplace\n",
    "        self.total_classes = total_classes\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.fitFeatures = []\n",
    "\n",
    "    def fit_distribution(self, data):\n",
    "\n",
    "        # mean = np.mean(data) # mean of the data\n",
    "        # std = np.std(data) # standard deviation of the data\n",
    "        # dist = norm(mean, std) # create a normal distribution with the mean and standard deviation\n",
    "\n",
    "        # return dist\n",
    "        return gaussian_kde(data)  # return the distribution\n",
    "\n",
    "    def laplace_smoothing(self, classes, length):\n",
    "        smooths = np.empty(self.total_classes, dtype=object)\n",
    "        for i in range(length):\n",
    "            smooths[i] = (classes[i] + self.laplace_smoothing_value) / \\\n",
    "                ((classes[i].size) +\n",
    "                 self.laplace_smoothing_value * self.n_features)\n",
    "\n",
    "        return smooths\n",
    "\n",
    "    def probability(self, data):\n",
    "        py = np.ones(self.total_classes)\n",
    "\n",
    "        for i in range(self.n_features):\n",
    "            for j in range(self.total_classes):\n",
    "                py[j] *= self.features['X'+str(i)+str(j)].pdf(data[i])\n",
    "\n",
    "        for i in range(self.total_classes):\n",
    "            py[i] *= self.prior[i]\n",
    "\n",
    "        return py\n",
    "\n",
    "    def laplace_probability(self, data):\n",
    "\n",
    "        py = np.ones(self.total_classes)\n",
    "        pdf = np.ones(self.total_classes)\n",
    "\n",
    "        for i in range(self.n_features):\n",
    "            for j in range(self.total_classes):\n",
    "                pdf[j] *= self.features['X'+str(i)+str(j)].pdf(data[i])\n",
    "\n",
    "            smooths = self.laplace_smoothing(pdf, self.total_classes)\n",
    "            for j in range(self.total_classes):\n",
    "                py[j] *= smooths[j]\n",
    "\n",
    "        for i in range(self.total_classes):\n",
    "            py[i] *= self.prior[i]\n",
    "\n",
    "        return py\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        X_training_class = np.empty(self.total_classes, dtype=object)\n",
    "        for i in range(self.total_classes):\n",
    "            X_training_class[i] = self.X_train[self.y_train == i]\n",
    "\n",
    "        self.prior = np.zeros(self.total_classes)\n",
    "        for i in range(self.total_classes):\n",
    "            # print('setting prior', i)\n",
    "            self.prior[i] = len(X_training_class[i]) / len(self.X_train)\n",
    "\n",
    "        self.n_features = self.X_train.shape[1]\n",
    "        print('Number of features: ', self.n_features)\n",
    "        self.features = {}\n",
    "\n",
    "        for i in range(self.n_features):\n",
    "            for j in range(self.total_classes):\n",
    "                self.features['X'+str(i)+str(j)\n",
    "                              ] = self.fit_distribution(X_training_class[j][:, i])\n",
    "\n",
    "    def predict(self, X_test, y_test):\n",
    "        y_predicted = []\n",
    "        y_second_predicted = []\n",
    "        y = []\n",
    "        for sample, target in zip(X_test, y_test):\n",
    "\n",
    "            if self.laplace:\n",
    "                py = self.laplace_probability(sample)\n",
    "\n",
    "            else:\n",
    "                py = self.probability(sample)\n",
    "\n",
    "            # print(\"Model predicted class {} and truth was {}\".format(np.argmax(py), target))\n",
    "            y_predicted.append(np.argmax(py))\n",
    "            # y_second_predicted.append(np.argsort(np.max(py, axis=0))[-2])\n",
    "            y.append(target)\n",
    "\n",
    "        y_predicted = np.array(y_predicted)\n",
    "        y = np.array(y)\n",
    "        return y_predicted, y_second_predicted, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def draw_matrix(true_positive, false_positive, false_negative, true_negative):\n",
    "    '''\n",
    "      Draw a confusion matrix.\n",
    "    '''\n",
    "    matrix = np.array([[true_positive, false_negative],\n",
    "                      [false_positive, true_negative]])\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.inferno_r)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def confusion_matrix(y, y_predicted, desired_class):\n",
    "    '''\n",
    "      Takes original classes and predicted classes as input\n",
    "    '''\n",
    "    print('total y', y.size)\n",
    "    print('total y_predicted', y_predicted.size)\n",
    "    actual = (y == desired_class)\n",
    "\n",
    "    predicted = (y_predicted == desired_class)\n",
    "    true_positive = (actual & predicted).sum()\n",
    "    false_positive = (actual & ~predicted).sum()\n",
    "    false_negative = (~actual & predicted).sum()\n",
    "    true_negative = (~actual & ~predicted).sum()\n",
    "\n",
    "    return true_positive, false_positive, false_negative, true_negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(given_y, y_predicted, classification_class='Kingdom'):\n",
    "    '''\n",
    "      Takes sampling technique as input\n",
    "\n",
    "      Returns:\n",
    "        precision, recall, accuracy\n",
    "    '''\n",
    "    for class_name in classes_dict.keys():\n",
    "        print(class_name)\n",
    "        print(dataset[dataset[classification_class] == int(\n",
    "            classes_dict.get(class_name))][classification_class].count())\n",
    "        true_positive, false_positive, false_negative, true_negative = confusion_matrix(\n",
    "            given_y, y_predicted, int(classes_dict.get(class_name)))\n",
    "        # draw_matrix(true_positive= true_positive, true_negative= true_negative, false_positive= false_positive, false_negative= false_negative)\n",
    "        print(\"true positive:\", true_positive)\n",
    "        print(\"false negative:\", false_negative)\n",
    "        print(\"false positive:\", false_positive)\n",
    "        print(\"true negative:\", true_negative)\n",
    "        print(\"Precision:\", true_positive / (true_positive + false_positive))\n",
    "        print(\"True Positive rate or Recall:\",\n",
    "              true_positive / (true_positive + false_negative))\n",
    "        print(\"specificity, selectivity or True Negative Rate:\",\n",
    "              true_negative / (true_negative + false_positive))\n",
    "        print(\"Accuracy:\", (true_positive + true_negative) /\n",
    "              (true_positive + false_positive + false_negative + true_negative))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_accuracy(y, y_predicted):\n",
    "    '''\n",
    "      Takes original classes and predicted classes as input\n",
    "    '''\n",
    "    actual = (y == y_predicted)\n",
    "    return actual.sum() / len(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20f3b51db45487e76e19b963685aeaff4d2f53ee3a54c0a9156da0ef575c3172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
